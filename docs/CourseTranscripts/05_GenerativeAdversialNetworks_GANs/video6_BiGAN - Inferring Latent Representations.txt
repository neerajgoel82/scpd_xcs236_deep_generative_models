00:00 -
00:05 - SPEAKER: The last thing we can briefly talk about
00:07 - is how to actually inferring latent representations in GANs.
00:12 - This is going to be a bit of a shift in terms of the topic
00:15 - but once you train a GAN, you have these latent variables
00:19 - that are mapped to observed variables
00:22 - and you might wonder, it kind of looks like a VAE, to what extent
00:26 - are you able to recover z given x?
00:29 - Let's say if you wanted features or something like that.
00:33 - And one way to do it, the problem
00:37 - is that it's no longer an invertible mapping
00:40 - and you don't have an encoder, right?
00:43 - So in the flow mapping setting, you just invert the generator.
00:48 - So given an x, you figure out what
00:49 - was the z that would be mapped to that x.
00:52 - In the variational autoencoder, you have the inference model,
00:55 - you have the encoder that is doing that job for you.
00:59 - In a GAN you don't quite have it.
01:01 - So one way to get features from a GAN
01:04 - is to actually look at the discriminator.
01:07 - So the discriminator is trying to distinguish real data
01:10 - from fake data, so presumably to do well
01:13 - at the job it has to figure out interesting features
01:16 - of the data.
01:17 - And so you can try to take the discriminator
01:20 - and fine tune it on different tasks
01:23 - or take the representations that you
01:26 - get towards the end of the neural network
01:30 - and hope that those features are actually useful for other tasks.
01:35 - If they were helpful for distinguishing real data
01:37 - from fake data, they might work for other tasks as well.
01:40 -
01:44 - If you want to get the z variables
01:48 - from the discriminator, from the generator
01:50 - kind of like in the VAE, then you
01:51 - need a different learning algorithm.
01:54 - And the problem is that in a regular GAN,
01:58 - you're basically just looking at the x part
02:01 - and somehow we need to change the training
02:03 - objective to also look at the z part and the latent variables.
02:07 - And the way to do it is to basically change
02:11 - the way you set up two sample tests or this likelihood
02:14 - free learning objectives to not only compare
02:17 - the x samples that you get from the model
02:20 - to the real data samples, but to also
02:23 - look at the representations, the kind of z's that produced
02:26 - the samples that you see.
02:29 - And the thing is that when you sample from the model,
02:34 - you get to see both the x and the z part
02:38 - because you're sampling them yourself.
02:40 - But in the data, you only get to see the x,
02:42 - there is no corresponding z.
02:45 - And so the way to do it is to essentially just like in a VAE
02:50 - introduce an encoder kind of network that
02:53 - will map x to the corresponding latent representation z.
02:59 - And so the architecture looks like this,
03:03 - it's called the BiGAN because it goes in two directions.
03:07 - So you have latent features that get mapped to data
03:10 - through the generator and then you
03:12 - have data that gets mapped to latent features
03:14 - through some encoder network.
03:17 - And then the job of the discriminator
03:20 - is to not only distinguish Gz from x, fake samples
03:25 - from real samples, but now the discriminator
03:28 - is going to try to distinguish fake samples with the latent
03:33 - variables from the model, from real samples and latent
03:37 - variables inferred from the encoder.
03:40 - So it's going to work in pairs of inputs x and z,
03:46 - where sometimes the x's are real,
03:48 - sometimes they are generated by the model and same thing.
03:50 - Sometimes the z are real, they are produced from the prior
03:54 - and sometimes they're produced by fitting real data
03:57 - to the encoder.
03:59 - And then basically everything is the same,
04:03 - then you train the generator, trying
04:08 - to fool the discriminator.
04:09 - You train the encoder and you train the discriminator
04:12 - trying to distinguish the samples and to the extent
04:15 - that this works.
04:19 - So the discriminator observes these pairs
04:21 - and the discriminator is trying to do as well as it can at
04:24 - distinguishing these two pairs.
04:27 - And after training, basically you can get the samples from g
04:33 - and you use the encoder to get the latent representations.
04:37 - And that's sort of the idea, it's pretty simple,
04:41 - it's an extension of GANs where you have another mapping which
04:47 - is also deterministic going from data to latent features
04:50 - and then you let the discriminator operate not only
04:53 - on data but on data, latent.
04:56 - And so to the extent that the discriminator cannot
04:59 - distinguish, the z's that are produced by the generative
05:02 - procedure from the z's that are produced by the encoder,
05:05 - then you might expect that the encoder is producing latent
05:08 - representations that are similar to the one that GANs would have
05:11 - used for generating a data point.
05:13 - And so effectively, the encoder is inverting
05:17 - the generative procedure, so it's
05:19 - very similar to a variational autoencoder
05:22 - except that E is a deterministic mapping
05:25 - and is not trained by minimizing KL divergences like in the ELBO,
05:29 - but it's trained by minimizing some kind of two sample
05:32 - test that is being optimized by a discriminator.
05:35 -
05:39 - It's the same sort of high level intuition.
05:43 - Yes, it's the concatenation, so you
05:45 - need to be able to distinguish pairs of real data.
05:47 -
05:50 - Features produced by the encoder from fake data,
05:53 - real features produced from the prior.
05:55 - So you cannot distinguish them, then the features that you get
05:58 - from the encoder E of x are going to be very similar
06:01 - to the z's that were actually used for generating data points.
06:04 - And so that's how the encoder is trained,
06:06 - everything is trained sort of adversarial.
06:09 - In this version there's only two options,
06:12 - but you could imagine a version where
06:17 - you're trying to enforce something stronger
06:18 - or maybe it's more like a cycle consistency
06:22 - that I guess we didn't have time to talk about today.
06:25 - Here there's only two, there is basically samples from the model
06:29 - and corresponding latents versus real data
06:33 - and corresponding latents.
06:35 - That's meant to be on real data, so let's say that then you
06:38 - want to do transfer learning or you want
06:41 - to do semisupervised learning or you
06:42 - want to do clustering or something,
06:44 - how do you get the features from a data point x?
06:47 - You don't use G because you don't know how to invert it,
06:50 - but you've trained a separate model, this encoder
06:52 - model that is basically trained to invert G, and so on.
06:56 - Real data at test time you just use
06:58 - E to get the corresponding latents.
07:02 - Like a VAE, two different pieces that
07:04 - are trained together to fool a discriminator in this case
07:09 - instead of minimizing an ELBO.
07:11 - This is all the same, they are sampled from a prior,
07:14 - so it's the same training as a GAN.
07:16 - So the z part doesn't change.
07:18 - So the z's are from the top half, the z's from the prior
07:24 - and then you pass them through the generator
07:26 - to produce data except that in a VAE
07:29 - that matching is done via KL divergence,
07:31 - here that matching is done adversarially basically.
07:36 - So the outputs of the encoder should
07:39 - be indistinguishable from z's that are sampled
07:42 - from the prior, where indistinguishable is measured
07:45 - not with respect to KL.
07:48 - Now it's measured with respect to a discriminator should not
07:51 - be able to distinguish that the stuff that comes out
07:54 - from the encoder when it's fed real data
07:56 - is different from the real latent variables
07:59 - that you sampled yourself from the prior.
08:02 - So it has the similar flavor to if you remember VAE,
08:05 - we had a very similar kind of intuition
08:07 - that what comes out from the encoder
08:09 - should be indistinguishable from the latent
08:13 - that you generate yourself.
08:15 - In that case, we were enforcing that indistinguishable using KL,
08:19 - here we're using a two sample test discriminator.
08:23 - So kind of like in VAE, you have a x,
08:26 - you feed it through the encoder and you
08:27 - get the corresponding latents and then
08:29 - you do whatever you need to do.
08:32 - Here at inference time if you want to just generate
08:34 - you don't use the encoder but if you want to get features then
08:37 - you still use the encoder just like here.
